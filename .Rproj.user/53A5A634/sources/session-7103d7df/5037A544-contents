---
title: "Homework 3 - Adv. Macro 1"
author: 'Davi Jorge'
format: pdf
editor: visual
editor_options: 
  chunk_output_type: console
---

# Homework 3 - Adv. Macro 1

**Questão 1.** Obtenha as séries mensais de inflação IPCA, IBC-Br (série 24363 do Banco Central), taxa de juros SELIC, índice de preço de commodities (série 27574 do BC) e taxa de câmbio. Calcule uma medida de taxa de juros real utilizando o IPCA como deflator. Use os dados a partir de janeiro de 2000. De posse disso, estime um VAR com dados mensais impondo um esquema de identificação recursivo (cholesky). Você deve usar Inflação IPCA, Taxa de juros real (a que você construiu), índice de preço das commodities, IBC-Br, e taxa de câmbio.

### Resposta:

As séries que utilizei foram: - IBC-Br - IPCA - geral - acumulado 12 meses\
- Taxa de juros definida pelo compom (Ultima objservação do mês) - índice de preço de commodities - Taxa de câmbio - Real / Dolar Americano - comercial - compra - fim período

```{r}
#| echo: false
#| warning: false
library(ipeadatar)
library(rbcb)
library(dplyr)
library(vars)
library(ggplot2)
library(PerformanceAnalytics)
library(hpfilter)
library(purrr)
library(tidyr)
library(seasonal)


```

```{r}
#| output: false
#| echo: false
#| warning: false

#series_ipea = ipeadatar::available_series()



serie_ipca <- ipeadatar::ipeadata('PRECOS12_IPCAG12') %>% 
  dplyr::mutate(value = rollapplyr((1 + value/100), 12, prod ,align = 'right' , fill = NA)-1) %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>% 
  dplyr::select(value) %>% 
  ts(start = 2003, frequency = 12)

serie_juros <- ipeadatar::ipeadata('BM366_TJOVER366') %>% 
  dplyr::group_by(lubridate::month(date), lubridate::year(date)) %>% 
  dplyr::slice(1) %>% 
  dplyr::ungroup() %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date <= as.Date("2025-02-02")) %>%
  dplyr::select(value) %>% 
  ts(start = 2003, frequency = 12)

serie_juros_real <- ((1 + serie_juros/100) / (1 + serie_ipca)) - 1

serie_ibcbr <- rbcb::get_series(24363) %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value = 2) %>%
  dplyr::mutate(value = log(value)) %>% 
  # hp2(0.5) %>%
  ts(start = 2003, frequency = 12)

serie_commodities <- rbcb::get_series(27574) %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value = 2) %>%
  dplyr::mutate(value = log(value)) %>% 
  ts(start = 2003, frequency = 12)

serie_cambio = ipeadatar::ipeadata('BM12_ERCF12') %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value) %>%
  ts(start = 2003, frequency = 12)


series = cbind(serie_ibcbr,  serie_ipca,  serie_cambio, serie_commodities,  serie_juros_real ) 

forecast::autoplot(series, facets = T)

length(serie_ibcbr)
length(serie_commodities)
length(serie_cambio)
length(serie_ipca)
length(serie_juros_real)

```

#### Criterios de informação

Utilizei para definir a quantidade de lags. O AIC e FPE sugeriram 4 e os outros 2, no entando, utilizei 12 lags, visto que algumas variaveis respondem mais lentamente a choques.

```{r}
#| output: false
#| echo: false
#| warning: false
vars::VARselect(series, type = 'both' )

```

#### Estimação do VAR

Para estimar o nosso VAR adicionei dummies para os meses para tentar capturar parte da sazonaliade. Além disso estimei o modelo com constante e tendência.

```{r}
#| output: false
#| echo: false
#| warning: false
names = lubridate::month(seq(1,12), label = T)

# Criar sequência de datas mensais
datas <- seq(as.Date("2003-01-01"), by = "month", length.out = 265)

# Criar dummies mensais
meses <- format(datas, "%m")
mes_fator <- factor(meses, levels = sprintf("%02d", 1:12))
dummies_mensais <- model.matrix(~ mes_fator - 1)  # matriz 266 x 12

dummies_mensais = as_tibble(dummies_mensais)
names(dummies_mensais) = names
# Colocar a variável endógena em um dataframe


var_model = vars::VAR(series, p = 12, type = "both", season = 12)
```

#### Testes de diagnóstico

Os testes de diagnósticos, foram Portmanteau para autocorrelação dos resíduos, assim como Breusch-Godfrey LM-statistic para testar conjuntamente os resíduos. Ambos deram signinificantes ao nível de 1% para ausência de autocorrelação. Para o teste de normalidade utilizei Jarque-Bera, Skewness e Kurtosis. Novamente, todos foram significantes à 1%. Por último, utilizei o teste Arch para heterocedasticidade, que também resultou em significante à 1% para homocedasticidade dos resíduos.

```{r}
#| output: false
#| echo: false
#| warning: false

vars::serial.test(var_model, lags.pt = 20, type = "PT.adjusted")
vars::serial.test(var_model, lags.pt = 20, type = "BG")
vars::normality.test(var_model)
vars::arch.test(var_model)
```

#### VAR Estrutural

A estrutura da matriz de restrições de cholesky, da mais exógena contemporaneamente para a mais endógena, foi dada por IBC-BR, IPCA, Preço das Commodities, Câmbio e Juros. Escolhemos como o mais endógeno o Juros porque o Banco Central observa todas as variaveis ao tomar a decisão da política. Assim como o Christiano, Eichenbaum and Evans (1999), o mais dificil de avaliar foi o preço das commodities, mas fizemos o teste deixando ela mais endogena e mais exogena, e os resultados não mudaram. E por isso fizemos o mesmo com o câmbio.

O método de estimação do VAR esstrutural foi o Maximo likelihood.

```{r}
#| echo: false
#| warning: false
#| output: false

a <- diag(1, 5)
a[lower.tri(a)] <- NA

svar_model <- vars::SVAR(var_model, Amat = a, estmethod = 'direct')
```
\newpage

#### IFR

As funções de impulso resposta (provavelmente por erro de identificação ou nos dados) não permite extrair nenhuma conclusão significante.

```{r}
#| echo: false
#| warning: false
#| fig.width: 10
#| fig.height: 6


irf = vars::irf(svar_model,impulse = "serie_juros_real", n.ahead = 36, runs = 100, ci = 0.68) 


respostas <- names(as_tibble(irf[1]$irf$serie_juros_real))

plots <- list()  # cria uma lista vazia

for (i in 1:5) {
  
  df <- tibble(
    periodo = 1:37,
    media = irf[1]$irf$serie_juros_real[, i],
    lower = irf[2]$Lower$serie_juros_real[, i],
    upper = irf[3]$Upper$serie_juros_real[, i]
  )
  
  p <- ggplot(df, aes(x = periodo)) +
    geom_line(aes(y = media), color = "blue") +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
    labs(title = paste("Resposta de", respostas[i]),
         y = "Resposta", x = "Período") +
    theme_minimal()
  
  plots[[i]] <- p  # salva o gráfico na lista
}

library(patchwork)
wrap_plots(plots, ncol = 3)  + 
  plot_layout(heights = c(1, 1.2, 1)) +
  plot_annotation(title = "Funções de Impulso-Resposta ao Choque em Juros Reais")


```
\newpage

#### FEVD

A série de juros real não pareceu importante (acredito que esteja errado)

```{r}
#| echo: false
#| warning: false
#| fig.width: 10
#| fig.height: 6



fevd_result = vars::fevd(svar_model, n.ahead = 36) 


# Converter FEVD em data.frame tidy
fevd_df <- map_dfr(names(fevd_result), function(var_name) {
  fevd_mat <- fevd_result[[var_name]]
  df <- as.data.frame(fevd_mat)
  df$Horizon <- 1:nrow(df)
  df_long <- pivot_longer(df, -Horizon, names_to = "Source", values_to = "Contribution")
  df_long$Variable <- var_name
  return(df_long)
})

ggplot(fevd_df, aes(x = Horizon, y = Contribution, fill = Source)) +
  geom_area(alpha = 0.8, color = "white") +
  facet_wrap(~ Variable, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  labs(title = "FEVD - Decomposição da Variância do Erro de Previsão",
       x = "Horizonte (meses)",
       y = "(%)",
       fill = "Choque") +
  theme(legend.position = "bottom",
        strip.text = element_text(face = "bold"))


```
\newpage

**Questão 2.** Refaça a estimação do VAR impondo restrição de sinais. Você deve usar Inflação IPCA, Taxa de juros real (a que você construiu), índice de preço das commodities, IBC-Br, e taxa de câmbio. Você pode usar ou Uhlig (2005), ou Mountford and Uhlig (2009) ou ainda Arias et al. (2018) como referência. Basta escolher um método e não precisa explicá-lo.

```{r}
#| echo: false
#| warning: false
#| output: false

library(VARsignR)


# Restricoes

constr <- c(+5,-2,-1)

modelo_varsign <- VARsignR::uhlig.reject(Y = series, nlags = 12,
                                         draws=200, subdraws=200, nkeep=1000, KMIN=1,
                                         KMAX=6, constrained=constr, constant=T, steps=30)

#summary(modelo_varsign)




# 
# fevdplot(fevd1, table=TRUE, label=vl, periods=c(1,10,20,30,40,50,60))
# 
# 
# shocks <- modelo_varsign$SHOCKS
# ss <- ts(t(apply(shocks,2,quantile,probs=c(0.5, 0.16, 0.84))), frequency=12, start=c(1966,1))
# plot(ss[,1], type="l", col="blue", ylab="Interest rate shock", ylim=c(min(ss), max(ss)))
# abline(h=0, col="black")
```

### Resposta

Para o calculo do VAR com restrições de sinais, eu restringi o sinal do log do IBC-Br e do IPCA, ambos negativamente a um choque positivo na política monetária. Eu optei por realizar 200x200 simulações, totalizando 40000. As bandas foram de 68%. Os resultados pareceram melhores em comparação ao Cholesky, ou seja, fizeram mais sentido econômico.
\newpage

#### IFR

![Impulso resposta a um choque no juros](ifr_varsign.png)

```{r}
#| echo: false
#| warning: false

irfs1 <- modelo_varsign$IRFS

VARsignR::irfplot(irfdraws = irfs1, type="median",  save=T, bands=c(0.32, 0.68),
        grid=TRUE, bw=FALSE)



```
\newpage   

#### FEVD

![Decomposição da variança de um choque no juros](FEVD%20VARSIGN.png)

```{r}
#| echo: false
#| warning: false
fevd1 <- modelo_varsign$FEVDS
VARsignR::fevdplot(fevd1, save=T, bands=c(0.16, 0.84), grid=TRUE,
         bw=FALSE, table=F, periods=NULL)

```
\newpage
**Questão 3.**  Neste exercício você deve reproduzir um dos modelos VAR que constam no Relatório Trimestral de Inflação de Setembro de 2012 <https://www.bcb.gov.br/htms/relinf/port/2012/09/ri201209P.pdf>), página 107. O primeiro VAR reproduz o modelo VAR I do relatório, enquanto o segundo reproduz parcialmente o VAR III. Você deve usar um critério para escolha do melhor modelo de previsão. Use os dados a partir de janeiro de 2000.

-   O VAR I: Preços livres, Preços administrados, câmbio, juros reais.

-   O VAR III: Preços livres, juros reais e IBC-Br. 

Projete a inflação de preços livres até o final 2024. Apresente seus resultados num gráfico e tabela.


### Resposta

Realizei a replicação dos quatro modelos VAR descritos na tabela da página 107 do Relatório. O segundo e o quarto VAR foram feitos com as séries dessazonalizadas e para fazer isso utlizei o método X-13ARIMA-SEATS. Calculei as defasagens para cada VAR e respectivamente foram 2, 4, 2 e 4 para os modelos. Após, eu utilizei método out-of-sample para fazer as previsões e caluclei o MSE de cada um. O modelo com menor MSE foi o VAR 3, que utiliza a series dessazonalizadas do IPCA - Preços livres, Produção Industrial (PIM-PF), e juros real.


```{r}
#| echo: false
#| warning: false
#| output: false

serie_plivres <- ipeadatar::ipeadata('BM12_IPCAPL12') %>% 
  dplyr::mutate(value = rollapplyr((1 + value/100), 12, prod ,align = 'right' , fill = NA)-1) %>%
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>% 
  dplyr::select(value) %>% 
  ts(start = 2003, frequency = 12)

serie_padm <- ipeadatar::ipeadata('BM12_IPCAPM12') %>% 
  dplyr::mutate(value = rollapplyr((1 + value/100), 12, prod ,align = 'right' , fill = NA)-1) %>%
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>% 
  dplyr::select(value) %>% 
  ts(start = 2003, frequency = 12)

serie_igpm <- ipeadatar::ipeadata('IGP12_IGPMG12') %>% 
  dplyr::mutate(value = rollapplyr((1 + value/100), 12, prod ,align = 'right' , fill = NA)-1) %>%
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>% 
  dplyr::select(value) %>% 
  ts(start = 2003, frequency = 12)

serie_juros <- ipeadatar::ipeadata('BM366_TJOVER366') %>% 
  dplyr::group_by(lubridate::month(date), lubridate::year(date)) %>% 
  dplyr::slice(1) %>% 
  dplyr::ungroup() %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date <= as.Date("2025-02-02")) %>%
  dplyr::select(value) %>% 
  ts(start = 2003, frequency = 12)

serie_juros_real <- ((1 + serie_juros/100) / (1 + final(seas(serie_igpm)))) - 1

serie_m1 <- ipeadatar::ipeadata('BM12_M1N12') %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value) %>%
  ts(start = 2003, frequency = 12)

serie_m4 <- ipeadatar::ipeadata('BM12_M4NCN12') %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value) %>%
  ts(start = 2003, frequency = 12)

serie_bm <- ipeadatar::ipeadata('BM12_M0N12') %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value) %>%
  ts(start = 2003, frequency = 12)

serie_m4_bm = serie_m4/serie_bm

serie_cambio = ipeadatar::ipeadata('BM12_ERCF12') %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value) %>%
  ts(start = 2003, frequency = 12)

serie_prodind = ipeadatar::ipeadata('PAN12_QIIGG12') %>% 
  dplyr::filter(date >= as.Date("2003-01-01") & date < as.Date("2025-02-01")) %>%
  dplyr::select(value) %>%
  ts(start = 2003, frequency = 12)


```


```{r}
#| echo: false
#| warning: false
#| fig.width: 10
#| fig.height: 6




# dessazonalizando series
serie_plivres_des <- final(seas(serie_plivres)) # 'final' extrai a série dessazonalizada
serie_prodind_des <- final(seas(serie_prodind))
serie_juros_real_des <- final(seas(serie_juros_real))
serie_m4_bm_des <- final(seas(serie_m4_bm))
serie_cambio_des <- final(seas(serie_cambio))


series_var1 <- cbind(serie_plivres, serie_padm, serie_cambio, serie_juros_real)
series_var2 <- cbind(serie_plivres_des, serie_m4_bm_des, serie_cambio_des, serie_juros_real_des)
series_var3 <- cbind(serie_plivres_des, serie_prodind_des, serie_juros_real_des)
series_var4 <- cbind(serie_plivres, serie_m1, serie_juros_real)

series_plot <- cbind(serie_plivres, serie_padm, serie_igpm, serie_cambio, serie_juros_real, serie_m1, serie_m4_bm_des, serie_prodind)

autoplot(series_plot, facets = T)
# autoplot(series_var2, facets = T)
# autoplot(series_var3, facets = T)
# autoplot(series_var4, facets = T)

# vars::VARselect(series_var1, type = 'both' ) # 2 defasagens
# vars::VARselect(series_var2, type = 'both' ) # 4 defasagens
# vars::VARselect(series_var3, type = 'both' ) # 2 defasagens
# vars::VARselect(series_var4, type = 'both' ) # 4 defasagens


# # VAR 1
# vars::serial.test(var1, lags.pt = 10, type = "PT.adjusted")
# vars::serial.test(var1, lags.pt = 10, type = "BG")
# vars::normality.test(var1)
# vars::arch.test(var1)
# 
# # VAR 2
# vars::serial.test(var2, lags.pt = 10, type = "PT.adjusted")
# vars::serial.test(var2, lags.pt = 10, type = "BG")
# vars::normality.test(var2)
# vars::arch.test(var2)
# 
# # VAR 3
# vars::serial.test(var3, lags.pt = 10, type = "PT.adjusted")
# vars::serial.test(var3, lags.pt = 10, type = "BG")
# vars::normality.test(var3)
# vars::arch.test(var3)
# 
# # VAR 3
# vars::serial.test(var4, lags.pt = 10, type = "PT.adjusted")
# vars::serial.test(var4, lags.pt = 10, type = "BG")
# vars::normality.test(var4)
# vars::arch.test(var4)


# Previsao VAR 1
treino_var1 <- series_var1 %>% head(n = nrow(series_var1) * .80)
observado_var1 <- series_var1 %>% tail(n = nrow(series_var1) * .20)

var1 <- vars::VAR(treino_var1, type = 'both', p = 2) 

forecast_var1 <- predict(var1, n.ahead = 53)

prev_var1 <- forecast_var1$fcst$serie_plivres[, "fcst"]

# Erro quadrático médio
mse_e <- mean((observado_var1[,"serie_plivres"] - prev_var1)^2)






# Previsao VAR 2
treino_var2 <- series_var2 %>% head(n = nrow(series_var2) * .80)
observado_var2 <- series_var2 %>% tail(n = nrow(series_var2) * .20)

var2 <- vars::VAR(treino_var2, type = 'both', p = 4) 

forecast_var2 <- predict(var2, n.ahead = 53)

prev_var2 <- forecast_var2$fcst$serie_plivres_des[, "fcst"]

# Erro quadrático médio
mse_e2 <- mean((observado_var2[,"serie_plivres_des"] - prev_var2)^2)








# Previsao VAR 3
treino_var3 <- series_var3 %>% head(n = nrow(series_var3) * .80)
observado_var3 <- series_var3 %>% tail(n = nrow(series_var3) * .20)

var3 <- vars::VAR(treino_var3, type = 'both', p = 2) 

forecast_var3 <- predict(var3, n.ahead = 53)

prev_var3 <- forecast_var3$fcst$serie_plivres_des[, "fcst"]

# Erro quadrático médio
mse_e3 <- mean((observado_var3[,"serie_plivres_des"] - prev_var3)^2)








# Previsao VAR 4
treino_var4 <- series_var4 %>% head(n = nrow(series_var4) * .80)
observado_var4 <- series_var4 %>% tail(n = nrow(series_var4) * .20)

var4 <- vars::VAR(treino_var4, type = 'both', p = 4) 

forecast_var4 <- predict(var4, n.ahead = 53)

prev_var4 <- forecast_var4$fcst$serie_plivres[, "fcst"]

# Erro quadrático médio
mse_e4 <- mean((observado_var4[,"serie_plivres"] - prev_var4)^2)





# Supondo que series_var3 é uma ts, zoo ou xts — convertemos para data.frame com data

# Datas originais
datas <- time(series_var3)
serie_total <- as.numeric(series_var3[, "serie_plivres_des"])

# Tamanhos
n_total <- length(serie_total)
n_treino <- nrow(treino_var3)
n_prev <- length(prev_var3)

# Criando vetor de previsão estendido com NA antes
prev_full1 <- rep(NA, n_total)
prev_full1[(n_treino + 1):(n_treino + n_prev)] <- prev_var1

# Criando vetor de previsão estendido com NA antes
prev_full2 <- rep(NA, n_total)
prev_full2[(n_treino + 1):(n_treino + n_prev)] <- prev_var2

# Criando vetor de previsão estendido com NA antes
prev_full3 <- rep(NA, n_total)
prev_full3[(n_treino + 1):(n_treino + n_prev)] <- prev_var3

# Criando vetor de previsão estendido com NA antes
prev_full4 <- rep(NA, n_total)
prev_full4[(n_treino + 1):(n_treino + n_prev)] <- prev_var4

# Observado out-of-sample (só para comparação visual)
obs_full <- rep(NA, n_total)
obs_full[(n_treino + 1):(n_treino + n_prev)] <- observado_var3[, "serie_plivres_des"]

# Data frame final para plot
df_plot <- data.frame(
  data = as.Date(datas),  # converte a data para Date se necessário
  serie = serie_total,
  previsto1 = prev_full1,
  previsto2 = prev_full2,
  previsto3 = prev_full3,
  previsto4 = prev_full4,
  observado = obs_full
)




ggplot(df_plot, aes(x = data)) +
  geom_line(aes(y = serie, color = "Histórico (Treino + Teste)")) +
  geom_line(aes(y = previsto1, color = "Previsão VAR 1"), linewidth = 1, linetype = "dashed") +
  geom_line(aes(y = previsto2, color = "Previsão VAR 2"), linewidth = 1, linetype = "dashed") +
  geom_line(aes(y = previsto3, color = "Previsão VAR 3"), linewidth = 1, linetype = "dashed") +
  geom_line(aes(y = previsto4, color = "Previsão VAR 4"), linewidth = 1, linetype = "dashed") +
  geom_line(aes(y = observado, color = "Observado (Fora da amostra)"), linewidth = 1) +
  labs(title = "Previsão out-of-sample - VAR(3)",
       y = "serie_plivres_des",
       x = "Data",
       color = "Série") +
  theme_minimal() +
  scale_color_manual(values = c("Histórico (Treino + Teste)" = "black",
                                "Previsão VAR 1" = "blue",
                                "Previsão VAR 2" = "green",
                                "Previsão VAR 3" = "orange",
                                "Previsão VAR 4" = "purple",
                                "Observado (Fora da amostra)" = "red"))

```